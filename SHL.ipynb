{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433cb957-ff5b-4312-b59b-5a5c4fb0aecf",
   "metadata": {},
   "source": [
    "# Grammar Scoring Engine from Speech Audio\r\n",
    "\r\n",
    "This project aims to build a machine learning model that automatically scores spoken language samples based on grammar quality. The dataset consists of audio files labeled with **MOS Likert Grammar Scores (0 to 5)**.\r\n",
    "\r",
    "  ðŸ§  Objective:\r\n",
    "To extract meaningful features from audio files (like MFCCs and Chroma) and train a regression model to predict grammar scores, evaluated using **Pearson Correlation**.\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10827079-4a28-4fe0-97f6-ad447863dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "    mfcc_std = np.std(mfcc.T, axis=0)\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma.T, axis=0)\n",
    "    chroma_std = np.std(chroma.T, axis=0)\n",
    "\n",
    "    return np.concatenate([mfcc_mean, mfcc_std, chroma_mean, chroma_std])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710baad-7dbc-444f-8121-e3e3005f9812",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\r\n",
    "We use libraries like `librosa` for audio feature extraction, `pandas` for data handling, and `scikit-learn`/`xgboost` for model training.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c02ae-fb3f-46b0-989f-6579b23cef45",
   "metadata": {},
   "source": [
    "##  Loading Dataset\r\n",
    "We read the training file which contains audio filenames and corresponding grammar scores. These will be used to extract features and train our models.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3d8c903-377d-4171-bf34-9ab77f8a63d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444/444 [04:22<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (444, 50)\n",
      "Labels shape: (444,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_csv_path = r\"C:\\Users\\pc\\OneDrive\\Desktop\\project\\Grammar Scoring Engine for spoken data samples\\shl-intern-hiring-assessment\\dataset\\train.csv\"\n",
    "train_audio_dir = r\"C:\\Users\\pc\\OneDrive\\Desktop\\project\\Grammar Scoring Engine for spoken data samples\\shl-intern-hiring-assessment\\dataset\\audios_train\"\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for file, label in tqdm(zip(train_df['filename'], train_df['label']), total=len(train_df)):\n",
    "    file_path = os.path.join(train_audio_dir, file)\n",
    "    try:\n",
    "        feats = extract_features(file_path)\n",
    "        features.append(feats)\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file}: {e}\")\n",
    "\n",
    "import numpy as np\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766287b0-6e9c-4c3d-9301-afe33ea9482a",
   "metadata": {},
   "source": [
    "## Feature Preparation\n",
    "\n",
    "We extract features for all training and test audio files and convert them into numerical arrays for model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544fd582-f857-4b13-93f3-5b16f20d4747",
   "metadata": {},
   "source": [
    "## Audio Feature Extraction\r\n",
    "\r\n",
    "We extract the following features for each audio file:\r\n",
    "- **MFCC Mean & Std**: Captures spectral shape\r\n",
    "- **Chroma Mean & Std**: Represents harmonic content\r\n",
    "\r\n",
    "This combination provides both timbral and pitch information useful for grammar scoring.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22246357-a9cd-4511-ac12-d719197b8c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444/444 [04:21<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (444, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "for file, label in tqdm(zip(train_df['filename'], train_df['label']), total=len(train_df)):\n",
    "    file_path = os.path.join(train_audio_dir, file)\n",
    "    try:\n",
    "        feats = extract_features(file_path)  \n",
    "        features.append(feats)\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file}: {e}\")\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(\"Feature shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81da01-8bc3-49c0-98c8-9ad78d79582b",
   "metadata": {},
   "source": [
    "## Model Training\r\n",
    "\r\n",
    "We train both a **Random Forest Regressor** and **XGBoost Regressor**, then take their average predictions for improved performance.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0071edf6-ee19-40be-870b-b6418b0733c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (355, 50)\n",
      "Validation shape: (89, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b425cc6-bd3b-4e02-a0e4-394161da20f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "872f3feb-f9ef-4e67-9abe-6c028a21c5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=200, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5224a9-d778-4db0-9735-03fed7b92884",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\r\n",
    "\r\n",
    "We use **MAE (Mean Absolute Error)** and **RMSE (Root Mean Squared Error)** for local evaluation. The leaderboard evaluates **Pearson Correlation**, which we aim to improve through feature engineering and ensembling.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f006e1b0-a7fd-4c03-ae95-360e36b2c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7470\n",
      "Root Mean Squared Error: 0.9309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "val_preds_rf = rf_model.predict(X_val)\n",
    "val_preds_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "val_preds_ensemble = (val_preds_rf + val_preds_xgb) / 2\n",
    "\n",
    "mae = mean_absolute_error(y_val, val_preds_ensemble)\n",
    "rmse = mean_squared_error(y_val, val_preds_ensemble, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "879a393f-8d8a-4f6b-b08f-252d81621591",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_rf = rf_model.predict(X_test)\n",
    "test_preds_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "final_test_preds = (test_preds_rf + test_preds_xgb) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e4b17-09a7-421f-a9d1-a2450cc098fc",
   "metadata": {},
   "source": [
    "## Submission File\r\n",
    "\r\n",
    "We create a CSV file with predictions for the test set. This file is uploaded for leaderboard evaluation.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aae76e06-1ff8-4503-9f6a-b503c51dfbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Submission file 'submission.csv' created!\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'filename': valid_filenames,\n",
    "    'mos': final_test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… Submission file 'submission.csv' created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca490159-ae93-4e18-a109-908bc01c393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>2.846406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.683649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.926985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>3.534893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>3.295017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  2.846406\n",
       "1   audio_800.wav  2.683649\n",
       "2    audio_68.wav  3.926985\n",
       "3  audio_1267.wav  3.534893\n",
       "4   audio_683.wav  3.295017"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'filename': valid_filenames,\n",
    "    'label': final_test_preds\n",
    "})\n",
    "\n",
    "# Sanity check: view the first few rows\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f15d9761-156e-44c4-8bdb-fa01126e6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (no index!)\n",
    "submission_df.to_csv('final_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c95cd13-da7b-448b-99a9-28f96ba027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"final_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2acbcb8-1549-4d97-83fc-cceb63c1d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b7752-16ce-4811-af98-19297c4450cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
